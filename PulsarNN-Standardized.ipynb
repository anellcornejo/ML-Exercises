{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de estrellas púlsares\n",
    "\n",
    "Mediante el siguiente notebook se pretenden clasificar estrellas como púlsares y no púlsares, utilizando los datos obtenidos de https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star. Inicialmente se estandarizarán los datos, para que toda la información quede contenida en un rango entre -1 y 1. Luego se analizará el rendimiento del modelo mediante las métricas accuracy y matriz de confusión. Finalmente, se estudiará la generalización de la red neuronal a nivel global realizando una curva de aprendizaje con el tamaño de la muestra como su hiper-parámetro.\n",
    "\n",
    " \n",
    "   \n",
    "Los púlsares son un tipo raro de estrellas de neutrones que producen emisiones de radio que son detectables aquí en la Tierra. A medida que los púlsares giran, su haz de emisión recorre el cielo, y cuando cruza nuestra línea de visión, produce un patrón detectable de emisión de radio. A medida que los púlsares giran rápidamente, este patrón se repite periódicamente. Por lo tanto, la búsqueda de un púlsar implica buscar señales de radio periódicas con radiotelescopios muy grandes.\n",
    "\n",
    "Cada púlsar produce un patrón de emisión ligeramente diferente, que varía levemente con cada rotación. Por lo tanto, una detección de señal potencial conocida como 'candidato' se promedia en muchas rotaciones del púlsar, según lo determinado por la duración de una observación. En ausencia de información adicional, cada candidato podría corresponder a un púlsar real. Sin embargo, en la práctica, casi todas las detecciones son causadas por interferencia de radiofrecuencia (RFI) y ruido, lo que hace que sea difícil encontrar señales legítimas.\n",
    "\n",
    "El aprendizaje automático nos permite crear algoritmos que sean capaces de etiquetar automáticamente a los candidatos de pulsar, lo que facilitará y agilizará el análisis de los datos. En este ejercicio en particular los casos legítimos de púlsares son una clase positiva minoritaria (etiquetados como 1), y los ejemplos falsos son la clase negativa mayoritaria (etiquetados como 0). El conjunto de datos contiene 16,259 ejemplos negativos causados por RFI o ruido, y 1,639 ejemplos de púlsares reales, con lo que queda un total de 17,898 datos. Todos estos ejemplos han sido verificados por anotadores humanos.\n",
    "\n",
    "\n",
    "\n",
    "## Obtención de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga y visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"pulsar_stars.csv\")\n",
    "#data = pd.read_csv(\"/home/anell/Projects/Pulsar-NN/pulsar_stars.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada candidato se describe mediante 8 variables continuas y una variable de clase única. Las primeras cuatro características son estadísticas simples obtenidas del perfil de pulso integrado, que básicamente se basa en una versión de la señal promedida en tiempo y en frecuencia, esta versión corresponde a la intensidad percibida en función de la fase de la señal.Las cuatro variables restantes se obtienen de manera similar de la curva DM-SNR. Estos se visualizan a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17893</th>\n",
       "      <td>136.429688</td>\n",
       "      <td>59.847421</td>\n",
       "      <td>-0.187846</td>\n",
       "      <td>-0.738123</td>\n",
       "      <td>1.296823</td>\n",
       "      <td>12.166062</td>\n",
       "      <td>15.450260</td>\n",
       "      <td>285.931022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17894</th>\n",
       "      <td>122.554688</td>\n",
       "      <td>49.485605</td>\n",
       "      <td>0.127978</td>\n",
       "      <td>0.323061</td>\n",
       "      <td>16.409699</td>\n",
       "      <td>44.626893</td>\n",
       "      <td>2.945244</td>\n",
       "      <td>8.297092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17895</th>\n",
       "      <td>119.335938</td>\n",
       "      <td>59.935939</td>\n",
       "      <td>0.159363</td>\n",
       "      <td>-0.743025</td>\n",
       "      <td>21.430602</td>\n",
       "      <td>58.872000</td>\n",
       "      <td>2.499517</td>\n",
       "      <td>4.595173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17896</th>\n",
       "      <td>114.507812</td>\n",
       "      <td>53.902400</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>-0.024789</td>\n",
       "      <td>1.946488</td>\n",
       "      <td>13.381731</td>\n",
       "      <td>10.007967</td>\n",
       "      <td>134.238910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17897</th>\n",
       "      <td>57.062500</td>\n",
       "      <td>85.797340</td>\n",
       "      <td>1.406391</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>188.306020</td>\n",
       "      <td>64.712562</td>\n",
       "      <td>-1.597527</td>\n",
       "      <td>1.429475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17898 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "0                           140.562500   \n",
       "1                           102.507812   \n",
       "2                           103.015625   \n",
       "3                           136.750000   \n",
       "4                            88.726562   \n",
       "...                                ...   \n",
       "17893                       136.429688   \n",
       "17894                       122.554688   \n",
       "17895                       119.335938   \n",
       "17896                       114.507812   \n",
       "17897                        57.062500   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "0                                          55.683782   \n",
       "1                                          58.882430   \n",
       "2                                          39.341649   \n",
       "3                                          57.178449   \n",
       "4                                          40.672225   \n",
       "...                                              ...   \n",
       "17893                                      59.847421   \n",
       "17894                                      49.485605   \n",
       "17895                                      59.935939   \n",
       "17896                                      53.902400   \n",
       "17897                                      85.797340   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "0                                       -0.234571   \n",
       "1                                        0.465318   \n",
       "2                                        0.323328   \n",
       "3                                       -0.068415   \n",
       "4                                        0.600866   \n",
       "...                                           ...   \n",
       "17893                                   -0.187846   \n",
       "17894                                    0.127978   \n",
       "17895                                    0.159363   \n",
       "17896                                    0.201161   \n",
       "17897                                    1.406391   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                                -0.699648                   3.199833   \n",
       "1                                -0.515088                   1.677258   \n",
       "2                                 1.051164                   3.121237   \n",
       "3                                -0.636238                   3.642977   \n",
       "4                                 1.123492                   1.178930   \n",
       "...                                    ...                        ...   \n",
       "17893                            -0.738123                   1.296823   \n",
       "17894                             0.323061                  16.409699   \n",
       "17895                            -0.743025                  21.430602   \n",
       "17896                            -0.024789                   1.946488   \n",
       "17897                             0.089520                 188.306020   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "0                                    19.110426   \n",
       "1                                    14.860146   \n",
       "2                                    21.744669   \n",
       "3                                    20.959280   \n",
       "4                                    11.468720   \n",
       "...                                        ...   \n",
       "17893                                12.166062   \n",
       "17894                                44.626893   \n",
       "17895                                58.872000   \n",
       "17896                                13.381731   \n",
       "17897                                64.712562   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                                  7.975532                      74.242225   \n",
       "1                                 10.576487                     127.393580   \n",
       "2                                  7.735822                      63.171909   \n",
       "3                                  6.896499                      53.593661   \n",
       "4                                 14.269573                     252.567306   \n",
       "...                                     ...                            ...   \n",
       "17893                             15.450260                     285.931022   \n",
       "17894                              2.945244                       8.297092   \n",
       "17895                              2.499517                       4.595173   \n",
       "17896                             10.007967                     134.238910   \n",
       "17897                             -1.597527                       1.429475   \n",
       "\n",
       "       target_class  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "17893             0  \n",
       "17894             0  \n",
       "17895             0  \n",
       "17896             0  \n",
       "17897             0  \n",
       "\n",
       "[17898 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_class\n",
       "0    16259\n",
       "1     1639\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"target_class\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "      <td>17898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.079968</td>\n",
       "      <td>46.549532</td>\n",
       "      <td>0.477857</td>\n",
       "      <td>1.770279</td>\n",
       "      <td>12.614400</td>\n",
       "      <td>26.326515</td>\n",
       "      <td>8.303556</td>\n",
       "      <td>104.857709</td>\n",
       "      <td>0.091574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.652935</td>\n",
       "      <td>6.843189</td>\n",
       "      <td>1.064040</td>\n",
       "      <td>6.167913</td>\n",
       "      <td>29.472897</td>\n",
       "      <td>19.470572</td>\n",
       "      <td>4.506092</td>\n",
       "      <td>106.514540</td>\n",
       "      <td>0.288432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.812500</td>\n",
       "      <td>24.772042</td>\n",
       "      <td>-1.876011</td>\n",
       "      <td>-1.791886</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>7.370432</td>\n",
       "      <td>-3.139270</td>\n",
       "      <td>-1.976976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.929688</td>\n",
       "      <td>42.376018</td>\n",
       "      <td>0.027098</td>\n",
       "      <td>-0.188572</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>14.437332</td>\n",
       "      <td>5.781506</td>\n",
       "      <td>34.960504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.078125</td>\n",
       "      <td>46.947479</td>\n",
       "      <td>0.223240</td>\n",
       "      <td>0.198710</td>\n",
       "      <td>2.801839</td>\n",
       "      <td>18.461316</td>\n",
       "      <td>8.433515</td>\n",
       "      <td>83.064556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.085938</td>\n",
       "      <td>51.023202</td>\n",
       "      <td>0.473325</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>5.464256</td>\n",
       "      <td>28.428104</td>\n",
       "      <td>10.702959</td>\n",
       "      <td>139.309331</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>192.617188</td>\n",
       "      <td>98.778911</td>\n",
       "      <td>8.069522</td>\n",
       "      <td>68.101622</td>\n",
       "      <td>223.392140</td>\n",
       "      <td>110.642211</td>\n",
       "      <td>34.539844</td>\n",
       "      <td>1191.000837</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "count                     17898.000000   \n",
       "mean                        111.079968   \n",
       "std                          25.652935   \n",
       "min                           5.812500   \n",
       "25%                         100.929688   \n",
       "50%                         115.078125   \n",
       "75%                         127.085938   \n",
       "max                         192.617188   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "count                                   17898.000000   \n",
       "mean                                       46.549532   \n",
       "std                                         6.843189   \n",
       "min                                        24.772042   \n",
       "25%                                        42.376018   \n",
       "50%                                        46.947479   \n",
       "75%                                        51.023202   \n",
       "max                                        98.778911   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "count                                17898.000000   \n",
       "mean                                     0.477857   \n",
       "std                                      1.064040   \n",
       "min                                     -1.876011   \n",
       "25%                                      0.027098   \n",
       "50%                                      0.223240   \n",
       "75%                                      0.473325   \n",
       "max                                      8.069522   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "count                         17898.000000               17898.000000   \n",
       "mean                              1.770279                  12.614400   \n",
       "std                               6.167913                  29.472897   \n",
       "min                              -1.791886                   0.213211   \n",
       "25%                              -0.188572                   1.923077   \n",
       "50%                               0.198710                   2.801839   \n",
       "75%                               0.927783                   5.464256   \n",
       "max                              68.101622                 223.392140   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "count                             17898.000000   \n",
       "mean                                 26.326515   \n",
       "std                                  19.470572   \n",
       "min                                   7.370432   \n",
       "25%                                  14.437332   \n",
       "50%                                  18.461316   \n",
       "75%                                  28.428104   \n",
       "max                                 110.642211   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "count                          17898.000000                   17898.000000   \n",
       "mean                               8.303556                     104.857709   \n",
       "std                                4.506092                     106.514540   \n",
       "min                               -3.139270                      -1.976976   \n",
       "25%                                5.781506                      34.960504   \n",
       "50%                                8.433515                      83.064556   \n",
       "75%                               10.702959                     139.309331   \n",
       "max                               34.539844                    1191.000837   \n",
       "\n",
       "       target_class  \n",
       "count  17898.000000  \n",
       "mean       0.091574  \n",
       "std        0.288432  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de los datos\n",
    "\n",
    "La estandarización de los datos puede mejorar rendimiento del algoritmo de clasificación, ya que localiza la información dentro de un rango acotado e igual para todas las características de cada dato. Para realizar este procedimiento, primero se debe obtener el promedio ($\\mu_i$) y el rango de variación ($S_i$) de cada una de las columnas que describe a cada ejemplo. Luego, se debe redefinir cada columa de dato como:\n",
    "\n",
    "$$ X_i = \\frac{X_i - \\mu_i}{S_i} $$\n",
    "\n",
    "en donde el rango, $S_i$, se calcula restando los valores máximos con los mínimos de cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_estand = data.copy()\n",
    "\n",
    "promedios = (data.mean())[0:-1] #Descartamos el promedio de la columna target_class\n",
    "rango = (data.max() - data.min())[0:-1] #Descarta el rengo de la columna target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mean of the integrated profile                  111.079968\n",
       " Standard deviation of the integrated profile     46.549532\n",
       " Excess kurtosis of the integrated profile         0.477857\n",
       " Skewness of the integrated profile                1.770279\n",
       " Mean of the DM-SNR curve                         12.614400\n",
       " Standard deviation of the DM-SNR curve           26.326515\n",
       " Excess kurtosis of the DM-SNR curve               8.303556\n",
       " Skewness of the DM-SNR curve                    104.857709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Mean of the integrated profile                   186.804688\n",
       " Standard deviation of the integrated profile      74.006869\n",
       " Excess kurtosis of the integrated profile          9.945533\n",
       " Skewness of the integrated profile                69.893508\n",
       " Mean of the DM-SNR curve                         223.178930\n",
       " Standard deviation of the DM-SNR curve           103.271778\n",
       " Excess kurtosis of the DM-SNR curve               37.679114\n",
       " Skewness of the DM-SNR curve                    1192.977813\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios = promedios.values.tolist() #pasa de dataframe a lista\n",
    "rango = rango.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)): #con esto redefinimos cada dato perteneciente a data_estand\n",
    "    data_estand.iloc[i, 0:8] = data_estand.iloc[i, 0:8] - promedios\n",
    "    data_estand.iloc[i, 0:8] = data_estand.iloc[i, 0:8].div(rango)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <th>Standard deviation of the integrated profile</th>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <th>Mean of the DM-SNR curve</th>\n",
       "      <th>Standard deviation of the DM-SNR curve</th>\n",
       "      <th>Excess kurtosis of the DM-SNR curve</th>\n",
       "      <th>Skewness of the DM-SNR curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157825</td>\n",
       "      <td>0.123424</td>\n",
       "      <td>-0.071633</td>\n",
       "      <td>-0.035338</td>\n",
       "      <td>-0.042184</td>\n",
       "      <td>-0.069875</td>\n",
       "      <td>-0.008706</td>\n",
       "      <td>-0.025663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045888</td>\n",
       "      <td>0.166645</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>-0.032698</td>\n",
       "      <td>-0.049006</td>\n",
       "      <td>-0.111031</td>\n",
       "      <td>0.060323</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.043170</td>\n",
       "      <td>-0.097395</td>\n",
       "      <td>-0.015538</td>\n",
       "      <td>-0.010289</td>\n",
       "      <td>-0.042536</td>\n",
       "      <td>-0.044367</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>-0.034943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.137416</td>\n",
       "      <td>0.143621</td>\n",
       "      <td>-0.054926</td>\n",
       "      <td>-0.034431</td>\n",
       "      <td>-0.040198</td>\n",
       "      <td>-0.051972</td>\n",
       "      <td>-0.037343</td>\n",
       "      <td>-0.042972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.119662</td>\n",
       "      <td>-0.079416</td>\n",
       "      <td>0.012368</td>\n",
       "      <td>-0.009254</td>\n",
       "      <td>-0.051239</td>\n",
       "      <td>-0.143871</td>\n",
       "      <td>0.158338</td>\n",
       "      <td>0.123816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17893</th>\n",
       "      <td>0.135702</td>\n",
       "      <td>0.179685</td>\n",
       "      <td>-0.066935</td>\n",
       "      <td>-0.035889</td>\n",
       "      <td>-0.050711</td>\n",
       "      <td>-0.137118</td>\n",
       "      <td>0.189673</td>\n",
       "      <td>0.151783</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17894</th>\n",
       "      <td>0.061426</td>\n",
       "      <td>0.039673</td>\n",
       "      <td>-0.035180</td>\n",
       "      <td>-0.020706</td>\n",
       "      <td>0.017006</td>\n",
       "      <td>0.177206</td>\n",
       "      <td>-0.142209</td>\n",
       "      <td>-0.080941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17895</th>\n",
       "      <td>0.044196</td>\n",
       "      <td>0.180881</td>\n",
       "      <td>-0.032024</td>\n",
       "      <td>-0.035959</td>\n",
       "      <td>0.039503</td>\n",
       "      <td>0.315144</td>\n",
       "      <td>-0.154039</td>\n",
       "      <td>-0.084044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17896</th>\n",
       "      <td>0.018350</td>\n",
       "      <td>0.099354</td>\n",
       "      <td>-0.027821</td>\n",
       "      <td>-0.025683</td>\n",
       "      <td>-0.047800</td>\n",
       "      <td>-0.125347</td>\n",
       "      <td>0.045235</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17897</th>\n",
       "      <td>-0.289165</td>\n",
       "      <td>0.530327</td>\n",
       "      <td>0.093362</td>\n",
       "      <td>-0.024047</td>\n",
       "      <td>0.787223</td>\n",
       "      <td>0.371699</td>\n",
       "      <td>-0.262774</td>\n",
       "      <td>-0.086698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17898 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean of the integrated profile  \\\n",
       "0                             0.157825   \n",
       "1                            -0.045888   \n",
       "2                            -0.043170   \n",
       "3                             0.137416   \n",
       "4                            -0.119662   \n",
       "...                                ...   \n",
       "17893                         0.135702   \n",
       "17894                         0.061426   \n",
       "17895                         0.044196   \n",
       "17896                         0.018350   \n",
       "17897                        -0.289165   \n",
       "\n",
       "        Standard deviation of the integrated profile  \\\n",
       "0                                           0.123424   \n",
       "1                                           0.166645   \n",
       "2                                          -0.097395   \n",
       "3                                           0.143621   \n",
       "4                                          -0.079416   \n",
       "...                                              ...   \n",
       "17893                                       0.179685   \n",
       "17894                                       0.039673   \n",
       "17895                                       0.180881   \n",
       "17896                                       0.099354   \n",
       "17897                                       0.530327   \n",
       "\n",
       "        Excess kurtosis of the integrated profile  \\\n",
       "0                                       -0.071633   \n",
       "1                                       -0.001261   \n",
       "2                                       -0.015538   \n",
       "3                                       -0.054926   \n",
       "4                                        0.012368   \n",
       "...                                           ...   \n",
       "17893                                   -0.066935   \n",
       "17894                                   -0.035180   \n",
       "17895                                   -0.032024   \n",
       "17896                                   -0.027821   \n",
       "17897                                    0.093362   \n",
       "\n",
       "        Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                                -0.035338                  -0.042184   \n",
       "1                                -0.032698                  -0.049006   \n",
       "2                                -0.010289                  -0.042536   \n",
       "3                                -0.034431                  -0.040198   \n",
       "4                                -0.009254                  -0.051239   \n",
       "...                                    ...                        ...   \n",
       "17893                            -0.035889                  -0.050711   \n",
       "17894                            -0.020706                   0.017006   \n",
       "17895                            -0.035959                   0.039503   \n",
       "17896                            -0.025683                  -0.047800   \n",
       "17897                            -0.024047                   0.787223   \n",
       "\n",
       "        Standard deviation of the DM-SNR curve  \\\n",
       "0                                    -0.069875   \n",
       "1                                    -0.111031   \n",
       "2                                    -0.044367   \n",
       "3                                    -0.051972   \n",
       "4                                    -0.143871   \n",
       "...                                        ...   \n",
       "17893                                -0.137118   \n",
       "17894                                 0.177206   \n",
       "17895                                 0.315144   \n",
       "17896                                -0.125347   \n",
       "17897                                 0.371699   \n",
       "\n",
       "        Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                                 -0.008706                      -0.025663   \n",
       "1                                  0.060323                       0.018890   \n",
       "2                                 -0.015068                      -0.034943   \n",
       "3                                 -0.037343                      -0.042972   \n",
       "4                                  0.158338                       0.123816   \n",
       "...                                     ...                            ...   \n",
       "17893                              0.189673                       0.151783   \n",
       "17894                             -0.142209                      -0.080941   \n",
       "17895                             -0.154039                      -0.084044   \n",
       "17896                              0.045235                       0.024628   \n",
       "17897                             -0.262774                      -0.086698   \n",
       "\n",
       "       target_class  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "17893             0  \n",
       "17894             0  \n",
       "17895             0  \n",
       "17896             0  \n",
       "17897             0  \n",
       "\n",
       "[17898 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_estand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_class\n",
       "0    16259\n",
       "1     1639\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_estand.groupby(\"target_class\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el proceso de estandarización es importante no redefinir los datos de las etiquetas, para no generar ambiguedades o confusiones con los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrucción de la red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crearán dos funciones. La primera de estas funciones recibe el número de características o columnas que describe a cada ejemplo, que en este ejercicio serían 8, y forma el modelo de la red neuronal a utilizar. La segunda función separá un conjunto de datos, recibido como input, en un set de entrenamiento y un set de validación, cuyos tamaños serán del 80% y 20% respectivamente, de un tamaño m entregado inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_dim=8):\n",
    "    inputs = Input(shape=(8,))\n",
    "\n",
    "    x = Dense(2)(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    # Compilación del modelo:\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_valid(data, m):\n",
    "\n",
    "    data = data.sample(frac=1)  \n",
    "\n",
    "    data_train = data[:int(0.8*m)]\n",
    "    data_valid = data[int(0.8*m):m]\n",
    "    \n",
    "    #train sample\n",
    "    ejemplos_train = data_train.values.tolist()\n",
    "    ejemplos_train = np.array(ejemplos_train)\n",
    "\n",
    "    features_train = ejemplos_train.transpose()\n",
    "    \n",
    "    X_train = features_train[0:8]\n",
    "    Y_train = features_train[8]\n",
    "\n",
    "    X_train = X_train.transpose()\n",
    "    \n",
    "    #valid_sample\n",
    "    ejemplos_valid = data_valid.values.tolist()\n",
    "    ejemplos_valid = np.array(ejemplos_valid)\n",
    "\n",
    "    features_valid = ejemplos_valid.transpose()\n",
    "    \n",
    "    X_valid = features_valid[0:8]\n",
    "    Y_valid = features_valid[8]\n",
    "\n",
    "    X_valid = X_valid.transpose()\n",
    "    \n",
    "    print(X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape)\n",
    "    \n",
    "    return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo: \n",
    "### Cálculo del error global mediante la métrica accuracy\n",
    "\n",
    "Utilizando las funciones definidas anteriormente, se generarán dos sets de datos; uno de entrenamiento, cuyo tamaño corresponderá al 80% del total de 17898 datos y un set de validación cruzada (cv), cuyo tamaño corresponderá al 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14318, 8) (14318,) (3580, 8) (3580,)\n"
     ]
    }
   ],
   "source": [
    "X_train_global, Y_train_global, X_cv_global, Y_cv_global = train_valid(data_est, len(data_estand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14318/14318 [==============================] - 27s 2ms/step - loss: 2.2162 - accuracy: 0.8323\n",
      "Epoch 2/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.2069 - accuracy: 0.9450\n",
      "Epoch 3/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1411 - accuracy: 0.9587\n",
      "Epoch 4/20\n",
      "14318/14318 [==============================] - 22s 2ms/step - loss: 0.1281 - accuracy: 0.9632\n",
      "Epoch 5/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1179 - accuracy: 0.9675\n",
      "Epoch 6/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1107 - accuracy: 0.9698\n",
      "Epoch 7/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1059 - accuracy: 0.9717\n",
      "Epoch 8/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1036 - accuracy: 0.9723\n",
      "Epoch 9/20\n",
      "14318/14318 [==============================] - 22s 2ms/step - loss: 0.0997 - accuracy: 0.9733\n",
      "Epoch 10/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0982 - accuracy: 0.9739\n",
      "Epoch 11/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0952 - accuracy: 0.9744\n",
      "Epoch 12/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0933 - accuracy: 0.9752\n",
      "Epoch 13/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0932 - accuracy: 0.9756\n",
      "Epoch 14/20\n",
      "14318/14318 [==============================] - 22s 2ms/step - loss: 0.0915 - accuracy: 0.9764\n",
      "Epoch 15/20\n",
      "14318/14318 [==============================] - 19s 1ms/step - loss: 0.0887 - accuracy: 0.9765\n",
      "Epoch 16/20\n",
      "14318/14318 [==============================] - 11s 790us/step - loss: 0.0857 - accuracy: 0.9767\n",
      "Epoch 17/20\n",
      "14318/14318 [==============================] - 11s 780us/step - loss: 0.0840 - accuracy: 0.9776\n",
      "Epoch 18/20\n",
      "14318/14318 [==============================] - 11s 789us/step - loss: 0.0840 - accuracy: 0.9775\n",
      "Epoch 19/20\n",
      "14318/14318 [==============================] - 11s 766us/step - loss: 0.0826 - accuracy: 0.9765\n",
      "Epoch 20/20\n",
      "14318/14318 [==============================] - 12s 847us/step - loss: 0.0824 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1d0afcbcd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Global_model = define_model(8)\n",
    "\n",
    "Global_model.fit(X_train_global,Y_train_global, epochs=20, batch_size=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14318/14318 [==============================] - 4s 274us/step\n",
      "Accuracy train: 97.22\n"
     ]
    }
   ],
   "source": [
    "# calculamos el error global del modelo para el conjunto de entrenamiento\n",
    "J_train, accuracy_train = Global_model.evaluate(X_train_global, Y_train_global)\n",
    "print('Accuracy train: %.2f' % (accuracy_train*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3580/3580 [==============================] - 1s 283us/step\n",
      "Accuracy CV: 96.93\n"
     ]
    }
   ],
   "source": [
    "# evaluación del modelo para el conjunto de validación cruzada\n",
    "J_cv, accuracy_cv = Global_model.evaluate(X_cv_global, Y_cv_global)\n",
    "print('Accuracy CV: %.2f' % (accuracy_cv*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos notar que la precisión global, tanto para el conjunto de entrenamiento, como para el set de validación, es bastante alta. Sin embargo, esto no nos asegura que el modelo construido sea generalizable a más datos ni que sea el más óptimo. \n",
    "\n",
    "El hecho de que este modelo haya dado un accuracy tan alto para los dos sets de datos se debe principalmente a que, dentro del total de los datos, la cantidad de ceros, o casos negativos, es mucho mayor que la cantidad total de unos, o casos positivos, presentando una población de $~81\\%$ y $~9\\%$ respectivamente. Con esta gran diferencia si el algoritmo realiza una mala predicción, por ejemplo si predice que una estrella es pulsar, siendo que en realidad no lo es, esto no afectará en gran medida a la precisión ya que hay una gran cantidad de ceros que solventen el problema.\n",
    "\n",
    "Otro factor que contribuyó a que este algoritmo presente una presición global alta, es que como los dos conjuntos de datos (de entrenamiento y de validación) fueron obtenidos a partir del mismo set o dominio, estos tenderán a presentar el mismo comportamiento, o uno muy similar, frente a un modelo de predicción.\n",
    "\n",
    "Debido a esto, es más recomendable evaluar este modelo de clasificación utilizando una matríz de confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo utilizando la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las predicciones entregadas por la red neuronal serán:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train = Global_model.predict(X_train_global) #sin aproximar\n",
    "prediccion_final_train = [round(x[0]) for x in prediccion_train] #aproxima a 1 o a 0\n",
    "\n",
    "prediccion_cv = Global_model.predict(X_cv_global) #sin aproximar\n",
    "prediccion_final_cv = [round(x[0]) for x in prediccion_cv] #aproxima a 1 o a 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos realizar la matriz de confusión, que en este ejemplo será una matriz de dimensión 2, ya que tenemos sólo dos posibles clases (0 y 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12876,   131],\n",
       "       [  267,  1044]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz de confusión para el set de entrenamiento\n",
    "confusion_matrix(Y_train_global,prediccion_final_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz de confusión del set de entrenamiento (tamaño igual a 14318) podemos ver que el modelo presentó 12876 verdaderos negativos (estrellas que no son púlsares las predice como no púlsares), 131 falsos positivos (estrellas que no son púlsares las predice como púlsares), 267 falsos negativos (estrellas que son púlsares las predice como no púlsares) y 1044 verdaderos positivos (estrella púlsares las predice como púlsares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3214,   38],\n",
       "       [  72,  256]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matriz de confusión para el set de validación cruzada\n",
    "confusion_matrix(Y_cv_global,prediccion_final_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la matriz de confusión del set de validación (tamaño igual a 3580) podemos ver que el modelo presentó 3214 verdaderos negativos (estrellas que no son púlsares las predice como no púlsares), 38 falsos positivos (estrellas que no son púlsares las predice como púlsares), 72 falsos negativos (estrellas que son púlsares las predice como no púlsares) y 256 verdaderos positivos (estrella púlsares las predice como púlsares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, podemos decir que la precisión global del modelo es alta, presentando un 97.22% de precisión para el set de entrenamiento y un 96.92% para el set de validación cruzada. Sin embargo, mediante la utilización de las matrices de confusión notamos que la tasa de identificación de pulsares es baja, para el set de entrenamiento esta tasa resultó ser 1044/(1044+256) = 0.8 y para el set de validación fue 256/(256+72) = 0.78."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva de aprendizaje\n",
    "\n",
    "Realizaremos una curva de aprendizaje cuyo hiper-parámetro será el tamaño de la muestra. Esta curva, nos permitirá analizar la cantidad de datos que son suficientes para lograr un rendimiento global óptimo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos una lista con distintos tamaños de muestra, en donde cada uno de estos será utilizado para crear un modelo que luego será evaluado para los sets de datos creados. Cabe notar que los números escogidos en la lista de los tamaños que se utilizarán presentan un crecimiento aproximadamente exponencial, esto se escogió así para visualizar de manera significante los cambios en la curva de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 8) (320,) (80, 8) (80,)\n",
      "Epoch 1/20\n",
      "320/320 [==============================] - 8s 23ms/step - loss: 0.7148 - accuracy: 0.2531\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5625\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.9031\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.9719\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.9750\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.9781\n",
      "Epoch 7/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.6050 - accuracy: 0.9812\n",
      "Epoch 8/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.9844\n",
      "Epoch 9/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.9781\n",
      "Epoch 10/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.9781\n",
      "Epoch 11/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.9781\n",
      "Epoch 12/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.9781\n",
      "Epoch 13/20\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.9750\n",
      "Epoch 14/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.9750: 0s - loss: 0.5262 - ac\n",
      "Epoch 15/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "320/320 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.9750\n",
      "Epoch 18/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4894 - accuracy: 0.9750\n",
      "Epoch 19/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4802 - accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.9750\n",
      "320/320 [==============================] - 1s 3ms/step\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "400 0.46656191647052764 0.9750000238418579 0.46472780108451844 0.9624999761581421\n",
      "(640, 8) (640,) (160, 8) (160,)\n",
      "Epoch 1/20\n",
      "640/640 [==============================] - 5s 9ms/step - loss: 0.6716 - accuracy: 0.8906\n",
      "Epoch 2/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.6296 - accuracy: 0.9656\n",
      "Epoch 3/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.9578\n",
      "Epoch 4/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.9547\n",
      "Epoch 5/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.4514 - accuracy: 0.9547\n",
      "Epoch 6/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.3982 - accuracy: 0.9531\n",
      "Epoch 7/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.3510 - accuracy: 0.9547\n",
      "Epoch 8/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.9578\n",
      "Epoch 9/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.2753 - accuracy: 0.9594\n",
      "Epoch 10/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.9594\n",
      "Epoch 11/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.2214 - accuracy: 0.9609\n",
      "Epoch 12/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.2011 - accuracy: 0.9609\n",
      "Epoch 13/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.9641\n",
      "Epoch 14/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.1696 - accuracy: 0.9641\n",
      "Epoch 15/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9656\n",
      "Epoch 16/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9672\n",
      "Epoch 17/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9688\n",
      "Epoch 18/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.1307 - accuracy: 0.9688\n",
      "Epoch 19/20\n",
      "640/640 [==============================] - 1s 1ms/step - loss: 0.1241 - accuracy: 0.9688\n",
      "Epoch 20/20\n",
      "640/640 [==============================] - 1s 2ms/step - loss: 0.1183 - accuracy: 0.9688\n",
      "640/640 [==============================] - 1s 2ms/step\n",
      "160/160 [==============================] - ETA:  - 0s 314us/step\n",
      "800 0.11547681018710136 0.96875 0.09799185991287232 0.9750000238418579\n",
      "(1280, 8) (1280,) (320, 8) (320,)\n",
      "Epoch 1/20\n",
      "1280/1280 [==============================] - 7s 5ms/step - loss: 0.5806 - accuracy: 0.9117\n",
      "Epoch 2/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.4555 - accuracy: 0.9117\n",
      "Epoch 3/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.3468 - accuracy: 0.9117\n",
      "Epoch 4/20\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.2712 - accuracy: 0.9117\n",
      "Epoch 5/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.2236 - accuracy: 0.9117\n",
      "Epoch 6/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1946 - accuracy: 0.9117\n",
      "Epoch 7/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1769 - accuracy: 0.9117\n",
      "Epoch 8/20\n",
      "1280/1280 [==============================] - 1s 920us/step - loss: 0.1655 - accuracy: 0.9117\n",
      "Epoch 9/20\n",
      "1280/1280 [==============================] - 1s 773us/step - loss: 0.1575 - accuracy: 0.9117\n",
      "Epoch 10/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1517 - accuracy: 0.9117\n",
      "Epoch 11/20\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.1471 - accuracy: 0.9117\n",
      "Epoch 12/20\n",
      "1280/1280 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9117\n",
      "Epoch 13/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1397 - accuracy: 0.9117\n",
      "Epoch 14/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1367 - accuracy: 0.9117\n",
      "Epoch 15/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1341 - accuracy: 0.9117\n",
      "Epoch 16/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1316 - accuracy: 0.9117\n",
      "Epoch 17/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1293 - accuracy: 0.9117\n",
      "Epoch 18/20\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.1271 - accuracy: 0.9117\n",
      "Epoch 19/20\n",
      "1280/1280 [==============================] - 2s 2ms/step - loss: 0.1249 - accuracy: 0.9117\n",
      "Epoch 20/20\n",
      "1280/1280 [==============================] - 2s 1ms/step - loss: 0.1229 - accuracy: 0.9117\n",
      "1280/1280 [==============================] - 1s 935us/step\n",
      "320/320 [==============================] - 0s 229us/step\n",
      "1600 0.12156805992126465 0.9117187261581421 0.11183424293994904 0.9125000238418579\n",
      "(2560, 8) (2560,) (640, 8) (640,)\n",
      "Epoch 1/20\n",
      "2560/2560 [==============================] - 8s 3ms/step - loss: 0.6433 - accuracy: 0.9062\n",
      "Epoch 2/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.5504 - accuracy: 0.9457\n",
      "Epoch 3/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.4717 - accuracy: 0.9563\n",
      "Epoch 4/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.4055 - accuracy: 0.9613\n",
      "Epoch 5/20\n",
      "2560/2560 [==============================] - 4s 2ms/step - loss: 0.3514 - accuracy: 0.9660\n",
      "Epoch 6/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.3080 - accuracy: 0.9656\n",
      "Epoch 7/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.2728 - accuracy: 0.9688\n",
      "Epoch 8/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.2440 - accuracy: 0.9699\n",
      "Epoch 9/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.2204 - accuracy: 0.9699\n",
      "Epoch 10/20\n",
      "2560/2560 [==============================] - 4s 2ms/step - loss: 0.2008 - accuracy: 0.9703\n",
      "Epoch 11/20\n",
      "2560/2560 [==============================] - 4s 2ms/step - loss: 0.1845 - accuracy: 0.9707\n",
      "Epoch 12/20\n",
      "2560/2560 [==============================] - 3s 1ms/step - loss: 0.1710 - accuracy: 0.9703\n",
      "Epoch 13/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.1595 - accuracy: 0.9711\n",
      "Epoch 14/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.1498 - accuracy: 0.9711\n",
      "Epoch 15/20\n",
      "2560/2560 [==============================] - 4s 2ms/step - loss: 0.1417 - accuracy: 0.9707\n",
      "Epoch 16/20\n",
      "2560/2560 [==============================] - 5s 2ms/step - loss: 0.1346 - accuracy: 0.9711: 2s - loss: 0.1242 - accu\n",
      "Epoch 17/20\n",
      "2560/2560 [==============================] - 4s 2ms/step - loss: 0.1287 - accuracy: 0.9727\n",
      "Epoch 18/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.1235 - accuracy: 0.9730\n",
      "Epoch 19/20\n",
      "2560/2560 [==============================] - 4s 1ms/step - loss: 0.1190 - accuracy: 0.9730\n",
      "Epoch 20/20\n",
      "2560/2560 [==============================] - 3s 1ms/step - loss: 0.1151 - accuracy: 0.9730\n",
      "2560/2560 [==============================] - 1s 574us/step\n",
      "640/640 [==============================] - 0s 262us/step\n",
      "3200 0.11316764852963387 0.97265625 0.1253956738859415 0.965624988079071\n",
      "(5120, 8) (5120,) (1280, 8) (1280,)\n",
      "Epoch 1/20\n",
      "5120/5120 [==============================] - 12s 2ms/step - loss: 0.4649 - accuracy: 0.9584\n",
      "Epoch 2/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.2077 - accuracy: 0.9604\n",
      "Epoch 3/20\n",
      "5120/5120 [==============================] - 8s 2ms/step - loss: 0.1324 - accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "5120/5120 [==============================] - 8s 1ms/step - loss: 0.1085 - accuracy: 0.9672\n",
      "Epoch 5/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0987 - accuracy: 0.9697\n",
      "Epoch 6/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0937 - accuracy: 0.9703\n",
      "Epoch 7/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0909 - accuracy: 0.9715\n",
      "Epoch 8/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0891 - accuracy: 0.9717\n",
      "Epoch 9/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0879 - accuracy: 0.9729\n",
      "Epoch 10/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0870 - accuracy: 0.9732\n",
      "Epoch 11/20\n",
      "5120/5120 [==============================] - 8s 2ms/step - loss: 0.0863 - accuracy: 0.9736\n",
      "Epoch 12/20\n",
      "5120/5120 [==============================] - 8s 2ms/step - loss: 0.0858 - accuracy: 0.9736\n",
      "Epoch 13/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0851 - accuracy: 0.9738\n",
      "Epoch 14/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0846 - accuracy: 0.9736\n",
      "Epoch 15/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0842 - accuracy: 0.9734\n",
      "Epoch 16/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0837 - accuracy: 0.9732\n",
      "Epoch 17/20\n",
      "5120/5120 [==============================] - 8s 1ms/step - loss: 0.0834 - accuracy: 0.9744\n",
      "Epoch 18/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0831 - accuracy: 0.9734\n",
      "Epoch 19/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0827 - accuracy: 0.9744\n",
      "Epoch 20/20\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0824 - accuracy: 0.9744\n",
      "5120/5120 [==============================] - 2s 384us/step\n",
      "1280/1280 [==============================] - 0s 243us/step\n",
      "6400 0.08205371398362331 0.9740234613418579 0.08974947959650308 0.9750000238418579\n",
      "(10240, 8) (10240,) (2560, 8) (2560,)\n",
      "Epoch 1/20\n",
      "10240/10240 [==============================] - 21s 2ms/step - loss: 0.3209 - accuracy: 0.9087\n",
      "Epoch 2/20\n",
      "10240/10240 [==============================] - 16s 2ms/step - loss: 0.1691 - accuracy: 0.9087\n",
      "Epoch 3/20\n",
      "10240/10240 [==============================] - 16s 2ms/step - loss: 0.1426 - accuracy: 0.9159\n",
      "Epoch 4/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.1255 - accuracy: 0.9695\n",
      "Epoch 5/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.1135 - accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.1048 - accuracy: 0.9726\n",
      "Epoch 7/20\n",
      "10240/10240 [==============================] - 12s 1ms/step - loss: 0.0988 - accuracy: 0.9731\n",
      "Epoch 8/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0944 - accuracy: 0.9740\n",
      "Epoch 9/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0912 - accuracy: 0.9746\n",
      "Epoch 10/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0888 - accuracy: 0.9750\n",
      "Epoch 11/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0869 - accuracy: 0.9752\n",
      "Epoch 12/20\n",
      "10240/10240 [==============================] - 15s 2ms/step - loss: 0.0853 - accuracy: 0.9756\n",
      "Epoch 13/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0840 - accuracy: 0.9753\n",
      "Epoch 14/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0830 - accuracy: 0.9760\n",
      "Epoch 15/20\n",
      "10240/10240 [==============================] - 14s 1ms/step - loss: 0.0821 - accuracy: 0.9766\n",
      "Epoch 16/20\n",
      "10240/10240 [==============================] - 14s 1ms/step - loss: 0.0813 - accuracy: 0.9769\n",
      "Epoch 17/20\n",
      "10240/10240 [==============================] - 16s 2ms/step - loss: 0.0805 - accuracy: 0.9764\n",
      "Epoch 18/20\n",
      "10240/10240 [==============================] - 14s 1ms/step - loss: 0.0802 - accuracy: 0.9765\n",
      "Epoch 19/20\n",
      "10240/10240 [==============================] - 15s 1ms/step - loss: 0.0794 - accuracy: 0.9770\n",
      "Epoch 20/20\n",
      "10240/10240 [==============================] - 15s 2ms/step - loss: 0.0789 - accuracy: 0.9768\n",
      "10240/10240 [==============================] - 6s 552us/step\n",
      "2560/2560 [==============================] - 1s 233us/step\n",
      "12800 0.07841876910242718 0.976855456829071 0.06340345224598423 0.983593761920929\n",
      "(14318, 8) (14318,) (3580, 8) (3580,)\n",
      "Epoch 1/20\n",
      "14318/14318 [==============================] - 25s 2ms/step - loss: 0.3122 - accuracy: 0.9021\n",
      "Epoch 2/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1530 - accuracy: 0.9094\n",
      "Epoch 3/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.1280 - accuracy: 0.9424\n",
      "Epoch 4/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0907 - accuracy: 0.9751\n",
      "Epoch 5/20\n",
      "14318/14318 [==============================] - 22s 2ms/step - loss: 0.0830 - accuracy: 0.9756\n",
      "Epoch 6/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0809 - accuracy: 0.9764\n",
      "Epoch 7/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0796 - accuracy: 0.9768\n",
      "Epoch 8/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0786 - accuracy: 0.9765\n",
      "Epoch 9/20\n",
      "14318/14318 [==============================] - 22s 2ms/step - loss: 0.0779 - accuracy: 0.9770\n",
      "Epoch 10/20\n",
      "14318/14318 [==============================] - 20s 1ms/step - loss: 0.0771 - accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0766 - accuracy: 0.9776\n",
      "Epoch 12/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0761 - accuracy: 0.9777\n",
      "Epoch 13/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0757 - accuracy: 0.9781\n",
      "Epoch 14/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0752 - accuracy: 0.9782\n",
      "Epoch 15/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0748 - accuracy: 0.9783\n",
      "Epoch 16/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0744 - accuracy: 0.9783\n",
      "Epoch 17/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0739 - accuracy: 0.9783 0s - loss: 0.073\n",
      "Epoch 18/20\n",
      "14318/14318 [==============================] - 21s 1ms/step - loss: 0.0737 - accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "14318/14318 [==============================] - 20s 1ms/step - loss: 0.0735 - accuracy: 0.9792\n",
      "Epoch 20/20\n",
      "14318/14318 [==============================] - 22s 2ms/step - loss: 0.0731 - accuracy: 0.9788\n",
      "14318/14318 [==============================] - 7s 462us/step\n",
      "3580/3580 [==============================] - 1s 264us/step\n",
      "17898 0.07268541643583612 0.9789076447486877 0.08655903969563586 0.97318434715271\n"
     ]
    }
   ],
   "source": [
    "lista_m = [400,800,1600,3200,6400,12800,len(data_est)]\n",
    "\n",
    "lista_Jtrain = []\n",
    "lista_Jcv = []\n",
    "\n",
    "lista_acc_train = []\n",
    "lista_acc_cv = []\n",
    "\n",
    "for m in lista_m:\n",
    "    \n",
    "    X_train, Y_train, X_cv, Y_cv = train_valid(data_estand, m)\n",
    "  \n",
    "    #restart the model\n",
    "    model = define_model(8)\n",
    "\n",
    "    #train the model\n",
    "    model.fit(X_train,Y_train, epochs=20, batch_size=10)\n",
    "    \n",
    "    Jtrain, accuracy_train = model.evaluate(X_train, Y_train)\n",
    "    \n",
    "    Jcv, accuracy_cv = model.evaluate(X_cv, Y_cv)\n",
    "    \n",
    "    lista_Jtrain.append(Jtrain)\n",
    "    lista_Jcv.append(Jcv)\n",
    "    \n",
    "    lista_acc_train.append(accuracy_train)\n",
    "    lista_acc_cv.append(accuracy_cv)\n",
    "    \n",
    "    print(m, Jtrain, accuracy_train, Jcv, accuracy_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización curva de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Costo')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lista_m,lista_Jtrain, label = \"Costo de entrenamiento\")\n",
    "plt.plot(lista_m,lista_Jcv,label = \"Costo de validación\")\n",
    "plt.legend()\n",
    "plt.title(\"Curva de Aprendizaje\")\n",
    "plt.xlabel(\"Tamaño de la muestra\")\n",
    "plt.ylabel(\"Costo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la curva de aprendizaje podemos notar que el error global de entrenamiento y de validación cruzada presentan un comportamiento bastante similar. Además, es posible concluir que la cantidad mínima u óptima de datos que se pueden utilizar en este problema es m = 10000, ya que en torno a este número, los errores se muestran bastante reducidos y estables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
