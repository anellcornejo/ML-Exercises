{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve 2\n",
    "\n",
    "Realizaremos una curva de aprendizaje para analizar la cantidad de datos que son suficientes para lograr un rendimiento global óptimo del modelo que predice si una estrella es un pulsar o no.\n",
    "\n",
    "Inicialmente importamos los datos necesarios, provenientes de  https://www.kaggle.com/sharansmenon/pulsar-star-pytorch/data.\n",
    "\n",
    "### Obtención de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/anell/Projects/Pulsar-NN/pulsar_stars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean-of-the-integrated-profile</th>\n",
       "      <th>Standard-deviation-of the-integrated-profile</th>\n",
       "      <th>Excess-kurtosis-of-the-integrated-profile</th>\n",
       "      <th>Skewness-of-the-integrated-profile</th>\n",
       "      <th>Mean-of-the-DM-SNR-curve</th>\n",
       "      <th>Standard-deviation-of-the-DM-SNR-curve</th>\n",
       "      <th>Excess-kurtosis-of-the-DM-SNR-curve</th>\n",
       "      <th>Skewness-of-the-DM-SNR-curve</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>127.367188</td>\n",
       "      <td>51.857960</td>\n",
       "      <td>-0.125432</td>\n",
       "      <td>-0.485281</td>\n",
       "      <td>2.326923</td>\n",
       "      <td>14.775555</td>\n",
       "      <td>10.117050</td>\n",
       "      <td>131.796158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>87.359375</td>\n",
       "      <td>44.800902</td>\n",
       "      <td>0.921022</td>\n",
       "      <td>1.626216</td>\n",
       "      <td>1.899666</td>\n",
       "      <td>12.323739</td>\n",
       "      <td>11.206985</td>\n",
       "      <td>175.221654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>52.296875</td>\n",
       "      <td>39.504422</td>\n",
       "      <td>2.605324</td>\n",
       "      <td>9.256109</td>\n",
       "      <td>39.709030</td>\n",
       "      <td>72.787699</td>\n",
       "      <td>1.601763</td>\n",
       "      <td>1.091597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>133.914062</td>\n",
       "      <td>53.718599</td>\n",
       "      <td>-0.045039</td>\n",
       "      <td>-0.246828</td>\n",
       "      <td>1.035117</td>\n",
       "      <td>9.819803</td>\n",
       "      <td>17.139964</td>\n",
       "      <td>389.481767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>126.664062</td>\n",
       "      <td>50.460888</td>\n",
       "      <td>0.074933</td>\n",
       "      <td>-0.520260</td>\n",
       "      <td>2.243311</td>\n",
       "      <td>16.298896</td>\n",
       "      <td>9.701440</td>\n",
       "      <td>108.661408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>93.054688</td>\n",
       "      <td>35.872454</td>\n",
       "      <td>0.255631</td>\n",
       "      <td>2.276567</td>\n",
       "      <td>0.385452</td>\n",
       "      <td>9.471101</td>\n",
       "      <td>24.800006</td>\n",
       "      <td>619.446717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>136.742188</td>\n",
       "      <td>44.391238</td>\n",
       "      <td>-0.221925</td>\n",
       "      <td>0.908085</td>\n",
       "      <td>2.105351</td>\n",
       "      <td>14.498377</td>\n",
       "      <td>10.131571</td>\n",
       "      <td>128.395149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>74.148438</td>\n",
       "      <td>40.887057</td>\n",
       "      <td>0.729262</td>\n",
       "      <td>1.707825</td>\n",
       "      <td>2.807692</td>\n",
       "      <td>22.848157</td>\n",
       "      <td>8.841503</td>\n",
       "      <td>80.670254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15267</th>\n",
       "      <td>95.828125</td>\n",
       "      <td>46.053486</td>\n",
       "      <td>0.419592</td>\n",
       "      <td>0.716984</td>\n",
       "      <td>1.593645</td>\n",
       "      <td>12.002944</td>\n",
       "      <td>12.926856</td>\n",
       "      <td>217.550196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17255</th>\n",
       "      <td>79.773438</td>\n",
       "      <td>42.144879</td>\n",
       "      <td>0.589811</td>\n",
       "      <td>1.462138</td>\n",
       "      <td>1.326087</td>\n",
       "      <td>12.147464</td>\n",
       "      <td>15.570881</td>\n",
       "      <td>284.774813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17898 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mean-of-the-integrated-profile  \\\n",
       "1740                        127.367188   \n",
       "10596                        87.359375   \n",
       "3774                         52.296875   \n",
       "7032                        133.914062   \n",
       "17500                       126.664062   \n",
       "...                                ...   \n",
       "12385                        93.054688   \n",
       "75                          136.742188   \n",
       "1190                         74.148438   \n",
       "15267                        95.828125   \n",
       "17255                        79.773438   \n",
       "\n",
       "        Standard-deviation-of the-integrated-profile  \\\n",
       "1740                                       51.857960   \n",
       "10596                                      44.800902   \n",
       "3774                                       39.504422   \n",
       "7032                                       53.718599   \n",
       "17500                                      50.460888   \n",
       "...                                              ...   \n",
       "12385                                      35.872454   \n",
       "75                                         44.391238   \n",
       "1190                                       40.887057   \n",
       "15267                                      46.053486   \n",
       "17255                                      42.144879   \n",
       "\n",
       "        Excess-kurtosis-of-the-integrated-profile  \\\n",
       "1740                                    -0.125432   \n",
       "10596                                    0.921022   \n",
       "3774                                     2.605324   \n",
       "7032                                    -0.045039   \n",
       "17500                                    0.074933   \n",
       "...                                           ...   \n",
       "12385                                    0.255631   \n",
       "75                                      -0.221925   \n",
       "1190                                     0.729262   \n",
       "15267                                    0.419592   \n",
       "17255                                    0.589811   \n",
       "\n",
       "        Skewness-of-the-integrated-profile   Mean-of-the-DM-SNR-curve  \\\n",
       "1740                             -0.485281                   2.326923   \n",
       "10596                             1.626216                   1.899666   \n",
       "3774                              9.256109                  39.709030   \n",
       "7032                             -0.246828                   1.035117   \n",
       "17500                            -0.520260                   2.243311   \n",
       "...                                    ...                        ...   \n",
       "12385                             2.276567                   0.385452   \n",
       "75                                0.908085                   2.105351   \n",
       "1190                              1.707825                   2.807692   \n",
       "15267                             0.716984                   1.593645   \n",
       "17255                             1.462138                   1.326087   \n",
       "\n",
       "        Standard-deviation-of-the-DM-SNR-curve  \\\n",
       "1740                                 14.775555   \n",
       "10596                                12.323739   \n",
       "3774                                 72.787699   \n",
       "7032                                  9.819803   \n",
       "17500                                16.298896   \n",
       "...                                        ...   \n",
       "12385                                 9.471101   \n",
       "75                                   14.498377   \n",
       "1190                                 22.848157   \n",
       "15267                                12.002944   \n",
       "17255                                12.147464   \n",
       "\n",
       "        Excess-kurtosis-of-the-DM-SNR-curve   Skewness-of-the-DM-SNR-curve  \\\n",
       "1740                              10.117050                     131.796158   \n",
       "10596                             11.206985                     175.221654   \n",
       "3774                               1.601763                       1.091597   \n",
       "7032                              17.139964                     389.481767   \n",
       "17500                              9.701440                     108.661408   \n",
       "...                                     ...                            ...   \n",
       "12385                             24.800006                     619.446717   \n",
       "75                                10.131571                     128.395149   \n",
       "1190                               8.841503                      80.670254   \n",
       "15267                             12.926856                     217.550196   \n",
       "17255                             15.570881                     284.774813   \n",
       "\n",
       "       target_class  \n",
       "1740              0  \n",
       "10596             0  \n",
       "3774              1  \n",
       "7032              0  \n",
       "17500             0  \n",
       "...             ...  \n",
       "12385             0  \n",
       "75                0  \n",
       "1190              0  \n",
       "15267             0  \n",
       "17255             0  \n",
       "\n",
       "[17898 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)  \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplos = data.values.tolist()\n",
    "ejemplos = np.array(ejemplos)\n",
    "\n",
    "features = ejemplos.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features[0:8]\n",
    "Y = features[8]\n",
    "\n",
    "X = X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión, para desarrollar la curva de aprendizaje, se crearán dos conjuntos de datos de igual tamaño. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:8949]\n",
    "Y_train = Y[0:8949]\n",
    "\n",
    "X_cv = X[8949:]\n",
    "Y_cv = Y[8949:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8949, 8), (8949,), (8949, 8), (8949,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_cv.shape, Y_cv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal\n",
    "\n",
    "Entrenaremos la red neuronal variando el tamaño del set de entrenamiento de uno en uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 21\n",
      "Trainable params: 21\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(8,))\n",
    "\n",
    "x = Dense(2)(inputs)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Dense(1)(x)\n",
    "x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "model = Model(inputs, x)\n",
    "\n",
    "\n",
    "# Compilación del modelo:\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ajustaremos y evaluaremos la red para cada tamaño de la muestra. Guardaremos el valor de los costos obtenidos al evaluar el set de entrenamiento y el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_m = [100,500,1000,2500,5000,7000,8948]\n",
    "lista_Jtrain = []\n",
    "lista_Jcv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 20.6298 - accuracy: 0.0400\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.2092 - accuracy: 0.0400\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7399 - accuracy: 0.0400\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3994 - accuracy: 0.0400\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.1408 - accuracy: 0.0500\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9849 - accuracy: 0.0600\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.9165 - accuracy: 0.0700\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.9104 - accuracy: 0.0700\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.9873 - accuracy: 0.0700\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.1042 - accuracy: 0.0700\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.2790 - accuracy: 0.0700\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 8.5013 - accuracy: 0.0700\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.7830 - accuracy: 0.0700\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.1326 - accuracy: 0.0700\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.4986 - accuracy: 0.0700\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9260 - accuracy: 0.0700\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.3857 - accuracy: 0.0700\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8837 - accuracy: 0.0700\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.4161 - accuracy: 0.0700\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.0013 - accuracy: 0.0700\n",
      "100/100 [==============================] - 1s 9ms/step\n",
      "100/100 [==============================] - 0s 253us/step\n",
      "Epoch 1/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 3.0796 - accuracy: 0.0560\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.8647 - accuracy: 0.1140\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 1.2192 - accuracy: 0.4560\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.9470 - accuracy: 0.7220\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8301 - accuracy: 0.8300\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7564 - accuracy: 0.8600\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7079 - accuracy: 0.8820\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6685 - accuracy: 0.8980\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6367 - accuracy: 0.9180\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6107 - accuracy: 0.9280\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5829 - accuracy: 0.9360\n",
      "Epoch 12/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5615 - accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5178 - accuracy: 0.9460\n",
      "Epoch 15/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4988 - accuracy: 0.9420\n",
      "Epoch 16/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4813 - accuracy: 0.9420\n",
      "Epoch 17/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4652 - accuracy: 0.9520\n",
      "Epoch 18/20\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4511 - accuracy: 0.9520\n",
      "Epoch 19/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4358 - accuracy: 0.9560\n",
      "Epoch 20/20\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4226 - accuracy: 0.9580\n",
      "500/500 [==============================] - 0s 315us/step\n",
      "500/500 [==============================] - 0s 363us/step\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4197 - accuracy: 0.9440\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.9460\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.3694 - accuracy: 0.95 - 1s 1ms/step - loss: 0.3678 - accuracy: 0.9530\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3451 - accuracy: 0.9560\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3246 - accuracy: 0.9590\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.3058 - accuracy: 0.9610\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2879 - accuracy: 0.9710\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2730 - accuracy: 0.9730\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2595 - accuracy: 0.9740\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2487 - accuracy: 0.9760\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2370 - accuracy: 0.9760\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2276 - accuracy: 0.9770\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2189 - accuracy: 0.9760\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.2113 - accuracy: 0.9770\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.2033 - accuracy: 0.9770\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1958 - accuracy: 0.9760\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9780\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9780\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1777 - accuracy: 0.9760\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1729 - accuracy: 0.9790\n",
      "1000/1000 [==============================] - 0s 217us/step\n",
      "1000/1000 [==============================] - 0s 253us/step\n",
      "Epoch 1/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1768 - accuracy: 0.9728\n",
      "Epoch 2/20\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1651 - accuracy: 0.9724\n",
      "Epoch 3/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1558 - accuracy: 0.9724\n",
      "Epoch 4/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1473 - accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1405 - accuracy: 0.9720\n",
      "Epoch 6/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1338 - accuracy: 0.9740\n",
      "Epoch 7/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1271 - accuracy: 0.9724\n",
      "Epoch 8/20\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.1231 - accuracy: 0.9716\n",
      "Epoch 9/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1190 - accuracy: 0.9744\n",
      "Epoch 10/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1162 - accuracy: 0.9736\n",
      "Epoch 11/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1121 - accuracy: 0.9728\n",
      "Epoch 12/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1087 - accuracy: 0.9732\n",
      "Epoch 13/20\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1074 - accuracy: 0.9724\n",
      "Epoch 14/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1060 - accuracy: 0.9740\n",
      "Epoch 15/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1045 - accuracy: 0.9724\n",
      "Epoch 16/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1022 - accuracy: 0.9732\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.1010 - accuracy: 0.9736\n",
      "Epoch 18/20\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0988 - accuracy: 0.9744\n",
      "Epoch 19/20\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.0990 - accuracy: 0.9736\n",
      "Epoch 20/20\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.0968 - accuracy: 0.9752\n",
      "2500/2500 [==============================] - 1s 219us/step\n",
      "2500/2500 [==============================] - 1s 232us/step\n",
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0951 - accuracy: 0.9744\n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0932 - accuracy: 0.9754\n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.0915 - accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0906 - accuracy: 0.9748\n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0898 - accuracy: 0.9760\n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0879 - accuracy: 0.9760\n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0883 - accuracy: 0.9750\n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.0889 - accuracy: 0.9744\n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.0871 - accuracy: 0.9758\n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0869 - accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.0862 - accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.0862 - accuracy: 0.9760\n",
      "Epoch 13/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0868 - accuracy: 0.9752\n",
      "Epoch 14/20\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.0858 - accuracy: 0.9760\n",
      "Epoch 15/20\n",
      "5000/5000 [==============================] - 4s 843us/step - loss: 0.0860 - accuracy: 0.9756\n",
      "Epoch 16/20\n",
      "5000/5000 [==============================] - 4s 797us/step - loss: 0.0850 - accuracy: 0.9752\n",
      "Epoch 17/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0847 - accuracy: 0.9752\n",
      "Epoch 18/20\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 0.0851 - accuracy: 0.9756\n",
      "Epoch 19/20\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 0.0847 - accuracy: 0.9754\n",
      "Epoch 20/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0847 - accuracy: 0.9758\n",
      "5000/5000 [==============================] - 1s 276us/step\n",
      "5000/5000 [==============================] - 1s 236us/step\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.0842 - accuracy: 0.9767\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 5s 759us/step - loss: 0.0839 - accuracy: 0.9771\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 5s 706us/step - loss: 0.0841 - accuracy: 0.9760\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 5s 710us/step - loss: 0.0834 - accuracy: 0.9764\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 6s 797us/step - loss: 0.0838 - accuracy: 0.9769\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 5s 698us/step - loss: 0.0832 - accuracy: 0.9757\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 6s 827us/step - loss: 0.0827 - accuracy: 0.9771\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 6s 794us/step - loss: 0.0832 - accuracy: 0.9760\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 5s 733us/step - loss: 0.0828 - accuracy: 0.9760\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 5s 718us/step - loss: 0.0833 - accuracy: 0.9757\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 5s 738us/step - loss: 0.0821 - accuracy: 0.9773\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 5s 754us/step - loss: 0.0824 - accuracy: 0.9763\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 5s 742us/step - loss: 0.0836 - accuracy: 0.9763\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 5s 689us/step - loss: 0.0820 - accuracy: 0.9767\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 5s 702us/step - loss: 0.0818 - accuracy: 0.9760\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 4s 630us/step - loss: 0.0823 - accuracy: 0.9761\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 5s 655us/step - loss: 0.0828 - accuracy: 0.9759\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 5s 743us/step - loss: 0.0818 - accuracy: 0.9769\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 6s 788us/step - loss: 0.0820 - accuracy: 0.9767\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 5s 700us/step - loss: 0.0810 - accuracy: 0.9774\n",
      "7000/7000 [==============================] - 1s 118us/step\n",
      "7000/7000 [==============================] - 1s 130us/step\n",
      "Epoch 1/20\n",
      "8949/8949 [==============================] - 7s 728us/step - loss: 0.0822 - accuracy: 0.9766\n",
      "Epoch 2/20\n",
      "8949/8949 [==============================] - 6s 718us/step - loss: 0.0822 - accuracy: 0.9772\n",
      "Epoch 3/20\n",
      "8949/8949 [==============================] - 7s 819us/step - loss: 0.0816 - accuracy: 0.9764\n",
      "Epoch 4/20\n",
      "8949/8949 [==============================] - 6s 690us/step - loss: 0.0810 - accuracy: 0.9764\n",
      "Epoch 5/20\n",
      "8949/8949 [==============================] - 6s 712us/step - loss: 0.0815 - accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "8949/8949 [==============================] - 7s 744us/step - loss: 0.0815 - accuracy: 0.9771\n",
      "Epoch 7/20\n",
      "8949/8949 [==============================] - 7s 770us/step - loss: 0.0818 - accuracy: 0.9769\n",
      "Epoch 8/20\n",
      "8949/8949 [==============================] - 6s 669us/step - loss: 0.0821 - accuracy: 0.9772\n",
      "Epoch 9/20\n",
      "8949/8949 [==============================] - 6s 707us/step - loss: 0.0817 - accuracy: 0.9765\n",
      "Epoch 10/20\n",
      "8949/8949 [==============================] - 6s 722us/step - loss: 0.0814 - accuracy: 0.9770\n",
      "Epoch 11/20\n",
      "8949/8949 [==============================] - 7s 742us/step - loss: 0.0814 - accuracy: 0.9769\n",
      "Epoch 12/20\n",
      "8949/8949 [==============================] - 7s 733us/step - loss: 0.0816 - accuracy: 0.9761\n",
      "Epoch 13/20\n",
      "8949/8949 [==============================] - 7s 755us/step - loss: 0.0813 - accuracy: 0.9759\n",
      "Epoch 14/20\n",
      "8949/8949 [==============================] - 7s 738us/step - loss: 0.0816 - accuracy: 0.9763\n",
      "Epoch 15/20\n",
      "8949/8949 [==============================] - 7s 736us/step - loss: 0.0806 - accuracy: 0.9760\n",
      "Epoch 16/20\n",
      "8949/8949 [==============================] - 6s 664us/step - loss: 0.0806 - accuracy: 0.9768\n",
      "Epoch 17/20\n",
      "8949/8949 [==============================] - 6s 719us/step - loss: 0.0798 - accuracy: 0.9770\n",
      "Epoch 18/20\n",
      "8949/8949 [==============================] - 6s 720us/step - loss: 0.0806 - accuracy: 0.9772\n",
      "Epoch 19/20\n",
      "8949/8949 [==============================] - 7s 740us/step - loss: 0.0808 - accuracy: 0.9769\n",
      "Epoch 20/20\n",
      "8949/8949 [==============================] - 6s 725us/step - loss: 0.0804 - accuracy: 0.9761\n",
      "8949/8949 [==============================] - 1s 113us/step\n",
      "8949/8949 [==============================] - 1s 116us/step\n"
     ]
    }
   ],
   "source": [
    "for i in lista_m:\n",
    "    X = X_train[0:i , :]\n",
    "    Y = Y_train[0:i]\n",
    "    \n",
    "    model.fit(X, Y, epochs=20, batch_size=10)\n",
    "    \n",
    "    Jtrain, accuracy_train = model.evaluate(X_train[0:i,:], Y_train[0:i])\n",
    "    \n",
    "    Jcv, accuracy_cv = model.evaluate(X_cv[0:i, :], Y_cv[0:i])\n",
    "    \n",
    "    lista_Jtrain.append(Jtrain)\n",
    "    lista_Jcv.append(Jcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización curva de aprendizaje\n",
    "\n",
    "Importamos la librería necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Costo')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lista_m,lista_Jtrain, label = \"Costo de entrenamiento\")\n",
    "plt.plot(lista_m,lista_Jcv,label = \"Costo de validación\")\n",
    "plt.legend()\n",
    "plt.title(\"Curva de Aprendizaje 2\")\n",
    "plt.xlabel(\"Tamaño de la muestra\")\n",
    "plt.ylabel(\"Costo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
